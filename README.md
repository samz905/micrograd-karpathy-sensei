## A tiny implementation of PyTorch's autograd engine
Based on Karpathy sensei's [micrograd](https://github.com/karpathy/micrograd) engine, this project implements a minimalist neural network library featuring backpropagation through automatic differentiation on a dynamically built DAG. I wanted to take my learnings to the next level so I added full support for vector values and mathematical operations like dot product and concat.